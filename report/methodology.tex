% !TEX root = ./report.tex

\clearpage
\section{Methodology}
\label{sec:methodology}

Using the ICs described in subsection~\ref{sub:meth:inlining_conditions}, the
inliner of this project has been tested using C-language programming files from
the SPEC2006 Benchmark Suite. This section first details the ICs, before
explaining how the files tested from the SPEC2006 Benchmark Suite were chosen.
Finally, we list the CNFs for each group of files from the SPEC2006 Benchmark
Suite the inliner ran said files with.

\subsection{The Inlining Conditions (ICs)}
\label{sub:meth:inlining_conditions}

The ICs utilized in this project are as follow:

\begin{itemize}

	\item \textbf{Node Count (NC)}

This function property equates to the number of C/C++ statements contained
within a function. A function's node count is an inliner condition we want
to utilize because it gives us an idea of the size of the  duplication if we
inline the function.

	\item \textbf{Loop Nesting Depth (LND)}

This call site property tells us how potentially useful it is to inline this
specific call site. The assumption is that most of a program's execution time is
spent within loops, so there is potentially more to gain if optimizations are
unveiled by inlining call sites inside nested loops.

	\item \textbf{Static Call Count (SCC)}

This property tells us how many call sites invoke this function in the program.
If this count is low, it may be worth inlining all the call sites and
eliminating the original function. For example, if the count is $1$, then the
call site can always be inlined, seeing as there is no risk of  duplication.

	\item \textbf{Parameter Count (PC)}

The greater the amount of parameters a function has, the greater the invocation
cost of said function. This is especially true when type conversion is required.
In some cases, the computational cost of an inlined with low node count may
be smaller than the cost of invoking it if it has many
parameters~\cite{AdaptvCompilAndInlingWaterman}.

	\item \textbf{Constant Parameter Count (CPC)}

This property tells us how many of the call site's parameters are constant at
the call site. Function invocations with constant parameters can often benefit
more from unveiled optimizations after inlining.

	\item \textbf{Calls In Node (CIN)}

This function property tells us how many call sites are located inside the
function the call site being evaluated invokes. Hence, it enables the finding of
leaf functions. Waterman~\cite{AdaptvCompilAndInlingWaterman} introduced this
parameter for two distinct reasons: leaf functions are often small and easily
inlined, and a high percentage of total execution time is spent in leaf
functions.

\end{itemize}

\subsection{The SPEC2006 Benchmark Suite files}
\label{sub:scheme:SPEC2006_files}

The SPEC2006 Benchmark Suite files were chosen with the following criteria:

\begin{enumerate}
	\item The Benchmark Suite program code files were written in 32-bit C.

	\item Clang-3.4 (on Ubuntu 14.04) was able to convert the inputted C files
to LLVM IR assembly with the \lstinline!-S! and \lstinline!-emit-llvm! flags.

	\item Jive was able to interpret all of the assembly commands in the
outputted .ll files and construct RVSDGs from them.

	\item The files could to be tested within a time limit of 200 seconds, run
single-process, single-thread, on a Intel(R) Core(TM) i5-4200M CPU @ 2.50GHz,
with 3072 KB cache size, Ubuntu 14.04 64-bit Linux distro.
\end{enumerate}

\unsure[inline]{Confirm with Nico that there were no more requirements.}

With these requirements, files from the following benchmarks were used for
testing:

\begin{multicols}{4}
	\begin{itemize}
		\item 400.perlbench
		\item 401.bzip2
		\item 403.gcc
		\item 429.mcf
		\item 433.milc
		\item 435.gromacs
		\item 445.gobmk
		\item 456.hmmer
		\item 458.sjeng
		\item 462.libquantum
		\item 464.h264ref
		\item 470.lbm
		\item 482.sphinx3
	\end{itemize}
\end{multicols}

See Appendix~\ref{app:SPEC2006_files_used} for the complete list of .c files
used for testing from each of the above benchmarks from SPEC2006.

\subsection{SPEC2006 Benchmark Heuristics}
\label{sub:scheme:SPEC2006_heuristics}

\todo[inline]{Say something about how we build the CNFs, the values used in
common across all benchmarks, and then the different values used for each
benchmark group of files. \newline
Remember to mention that we profile them first, and the profiling data we use to
build our CNFs are in the results section.}
